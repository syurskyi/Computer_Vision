{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV's dnn.blobFromImage to perform Neural Style Transfer on an input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Using Model: la_muse\n",
      "2. Using Model: feathers\n",
      "3. Using Model: composition_vii\n",
      "4. Using Model: mosaic\n",
      "5. Using Model: the_scream\n",
      "6. Using Model: udnie\n",
      "7. Using Model: starry_night\n",
      "8. Using Model: candy\n",
      "9. Using Model: the_wave\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "\n",
    "# Load our t7 neural transfer models\n",
    "model_file_path = \"./models/\"\n",
    "model_file_paths = [f for f in listdir(model_file_path) if isfile(join(model_file_path, f))]\n",
    "\n",
    "# Load our test image\n",
    "img = cv2.imread(\"images/n2.jpg\")\n",
    "\n",
    "# Loop through and applying each model style our input image\n",
    "for (i,model) in enumerate(model_file_paths):\n",
    "    # print the model being used\n",
    "    print(str(i+1) + \". Using Model: \" + str(model)[:-3])    \n",
    "    style = cv2.imread(\"./art/\"+str(model)[:-3]+\".jpg\")\n",
    "    # loading our neural style transfer model \n",
    "    neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path+ model)\n",
    "\n",
    "    # Let's resize to a fixed height of 640 (feel free to change)\n",
    "    height, width = int(img.shape[0]), int(img.shape[1])\n",
    "    newWidth = int((640 / height) * width)\n",
    "    resizedImg = cv2.resize(img, (newWidth, 640), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # Create our blob from the image and then perform a forward pass run of the network\n",
    "    inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640),\n",
    "                               (103.939, 116.779, 123.68), swapRB=False, crop=False)\n",
    "\n",
    "    neuralStyleModel.setInput(inpBlob)\n",
    "    output = neuralStyleModel.forward()\n",
    "\n",
    "    # Reshaping the output tensor, adding back  the mean subtraction \n",
    "    # and re-ordering the channels \n",
    "    output = output.reshape(3, output.shape[2], output.shape[3])\n",
    "    output[0] += 103.939\n",
    "    output[1] += 116.779\n",
    "    output[2] += 123.68\n",
    "    output /= 255\n",
    "    output = output.transpose(1, 2, 0)\n",
    "    \n",
    "    #Display our original image, the style being applied and the final Neural Style Transfer\n",
    "    cv2.imshow(\"Original\", img)\n",
    "    cv2.imshow(\"Style\", style)\n",
    "    cv2.imshow(\"Neural Style Transfers\", output)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying this to our webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Our sketch generating function\n",
    "def NeuralStyleTransfer(img, model, size = 320, upscale = 1):\n",
    "    \n",
    "    model_file_path = \"./models/\" \n",
    "    style = cv2.imread(\"./art/\"+str(model)[:-3]+\".jpg\")\n",
    "    # loading our neural style transfer model \n",
    "    neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path+ model+\".t7\")\n",
    "\n",
    "    # Let's resize to a fixed height of 640 (feel free to change)\n",
    "    height, width = int(img.shape[0]), int(img.shape[1])\n",
    "    newWidth = int((size / height) * width)\n",
    "    resizedImg = cv2.resize(img, (newWidth, size), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # Create our blob from the image and then perform a forward pass run of the network\n",
    "    inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, size),\n",
    "                               (103.939, 116.779, 123.68), swapRB=False, crop=False)\n",
    "\n",
    "    neuralStyleModel.setInput(inpBlob)\n",
    "    output = neuralStyleModel.forward()\n",
    "\n",
    "    # Reshaping the output tensor, adding back  the mean subtraction \n",
    "    # and re-ordering the channels \n",
    "    output = output.reshape(3, output.shape[2], output.shape[3])\n",
    "    output[0] += 103.939\n",
    "    output[1] += 116.779\n",
    "    output[2] += 123.68\n",
    "    output /= 255\n",
    "    output = output.transpose(1, 2, 0)\n",
    "    output = cv2.resize(output, None, fx=upscale, fy=upscale, interpolation = cv2.INTER_LINEAR)\n",
    "    return output\n",
    "\n",
    "\n",
    "# Initialize webcam, cap is the object provided by VideoCapture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# la_muse, feathers, composition_vii, mosaic, the_scream, udnie, starry_night, candy, the_wave\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Neural Style Transfers', NeuralStyleTransfer(frame, \"mosaic\", 320, 2))\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "# Release camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
