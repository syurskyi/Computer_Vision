<h4><strong>Single Shot Detectors (SSDs) have been recently Added to OpenCV</strong></h4><p><br></p><ul><li><p>SSD’s use multi-sale features and default boxes as well as dropping the resolution images to improve speed.</p></li><li><p>This allows SSD’s to achieve real-time speed with almost no drop (sometimes even improved) accuracy.</p></li><li><p>SSDs are faster than Faster R-CNN but less accurate in detecting small objects.</p></li><li><p>Accuracy increases if we increase the number of default boxes as well as better designed boxes</p></li><li><p>Multi-scale feature maps improve detection at varying scales.</p></li></ul><figure><img src="https://udemy-images.s3.amazonaws.com:443/redactor/raw/2019-04-24_18-37-13-70faedb68a7150d9c0870de088770421.JPG"><strong>SSD’s are composed of two main parts:</strong></figure><ul><li><p>Feature Map Extractor (VGG16 was used in the published paper but ResNet or DenseNet may provide better results))</p></li><li><p>Convolution Filter for Object Detection</p></li></ul><p><strong>How do they work?</strong></p><ul><li><p>Using the VGG16’s CONV4_3 Layer it makes 4 to 6 (user set) object predictions (shown below) for each cell.</p></li><li><p>It predicts the class scores and adds one extra for no object being found.</p></li><li><p>Fewer cells allow larger objects to be detected (e.g. the dog and right rightmost diagram with the red box) and large number of cells allow more granular detection of smaller objects (e.g. the cat).</p></li></ul><figure><img src="https://udemy-images.s3.amazonaws.com:443/redactor/raw/2019-04-24_18-38-04-dfe513ddf20eb1c49ff2864478d6b42b.JPG"></figure><p><strong>Let's implement an SSD using OpenCV</strong></p><p><br></p><p>In the code below we, we are able to use two (2) pre-trained SSD models. The first is a 20 class model trained in Caffe, the other is a TensorFlow model trained using the COCO dataset for 90 classes.</p><p><strong>See attached files in the resources for:</strong></p><ul><li><p>The code below as a ipynb file and py file (note the py file is the original supplied by OpenCV)</p></li><li><p>The pbtxt files for both Caffe and TensorFlow Models</p></li><li><p>The Text graph for both models</p></li></ul><p>The code can work using both an input video file, webcam and be easily be modified to work on single images. </p><pre class="prettyprint linenums"># This script is used to demonstrate MobileNet-SSD network using OpenCV deep learning module.
#
# It works with model taken from https://github.com/chuanqi305/MobileNet-SSD/ that
# was trained in Caffe-SSD framework, https://github.com/weiliu89/caffe/tree/ssd.
# Model detects objects from 20 classes.
#
# Also TensorFlow model from TensorFlow object detection model zoo may be used to
# detect objects from 90 classes:
# http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz
# Text graph definition must be taken from opencv_extra:
# https://github.com/opencv/opencv_extra/tree/master/testdata/dnn/ssd_mobilenet_v1_coco.pbtxt
import numpy as np
import cv2

inWidth = 300
inHeight = 300
WHRatio = inWidth / float(inHeight)
inScaleFactor = 0.007843
meanVal = 127.5

videoPath = None 
Caffe = False 
if Caffe:
    prototxt = "MobileNetSSD_deploy.prototxt"
    weights = "MobileNetSSD_deploy.caffemodel"
    num_classes = 20
else:
    prototxt = "ssd_mobilenet_v1_coco.pbtxt"
    weights = "frozen_inference_graph.pb"
    num_classes = 90
thr = 0.2

if __name__ == "__main__":

    if num_classes == 20:
        net = cv2.dnn.readNetFromCaffe(prototxt, weights)
        swapRB = False
        classNames = { 0: 'background',
            1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat',
            5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', 9: 'chair',
            10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse',
            14: 'motorbike', 15: 'person', 16: 'pottedplant',
            17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor' }
    else:
        assert(num_classes == 90)
        net = cv2.dnn.readNetFromTensorflow(weights, prototxt)
        swapRB = True
        classNames = { 0: 'background',
            1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus',
            7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant',
            13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat',
            18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear',
            24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag',
            32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard',
            37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove',
            41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle',
            46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon',
            51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange',
            56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut',
            61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed',
            67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse',
            75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven',
            80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock',
            86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush' }

    if videoPath:
        cap = cv2.VideoCapture(videoPath)
    else:
        cap = cv2.VideoCapture(0)

    while True:
        # Capture frame-by-frame
        ret, frame = cap.read()
        blob = cv2.dnn.blobFromImage(frame, inScaleFactor, (inWidth, inHeight), (meanVal, meanVal, meanVal), swapRB)
        net.setInput(blob)
        detections = net.forward()

        cols = frame.shape[1]
        rows = frame.shape[0]

        if cols / float(rows) &gt; WHRatio:
            cropSize = (int(rows * WHRatio), rows)
        else:
            cropSize = (cols, int(cols / WHRatio))

        y1 = int((rows - cropSize[1]) / 2)
        y2 = y1 + cropSize[1]
        x1 = int((cols - cropSize[0]) / 2)
        x2 = x1 + cropSize[0]
        frame = frame[y1:y2, x1:x2]

        cols = frame.shape[1]
        rows = frame.shape[0]

        for i in range(detections.shape[2]):
            confidence = detections[0, 0, i, 2]
            if confidence &gt; thr:
                class_id = int(detections[0, 0, i, 1])

                xLeftBottom = int(detections[0, 0, i, 3] * cols)
                yLeftBottom = int(detections[0, 0, i, 4] * rows)
                xRightTop   = int(detections[0, 0, i, 5] * cols)
                yRightTop   = int(detections[0, 0, i, 6] * rows)

                cv2.rectangle(frame, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop),
                              (0, 255, 0))
                if class_id in classNames:
                    label = classNames[class_id] + ": " + str(confidence)
                    labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)

                    yLeftBottom = max(yLeftBottom, labelSize[1])
                    cv2.rectangle(frame, (xLeftBottom, yLeftBottom - labelSize[1]),
                                         (xLeftBottom + labelSize[0], yLeftBottom + baseLine),
                                         (255, 255, 255), cv2.FILLED)
                    cv2.putText(frame, label, (xLeftBottom, yLeftBottom),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))

        cv2.imshow("detections", frame)
        if cv2.waitKey(1) &gt;= 0:
            break
            
cap.release()            
cv2.destroyAllWindows()</pre>